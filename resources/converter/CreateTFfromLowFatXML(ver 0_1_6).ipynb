{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Text-Fabric from LowFat XML trees (0.1.6)\n",
    "The source data for the conversion are the LowFat XML trees files representing the macula-greek version of the Nestle 1904 Greek New Testment.  The most recent source data can be found on github https://github.com/Clear-Bible/macula-greek/tree/main/Nestle1904/lowfat. Attribution: \"MACULA Greek Linguistic Datasets, available at https://github.com/Clear-Bible/macula-greek/\". \n",
    "\n",
    "The production of the Text-Fabric files consist of two steps. First the creation of piclke files (part 1). Secondly the actual Text-Fabric creation process (part 2). Both steps are independent allowing to start from Part 2 by using the pickle files as input. \n",
    "\n",
    "Be advised that this Text-Fabric version is a test version (proof of concept) and requires further finetuning, especialy with regards of nomenclature and presentation of (sub)phrases and clauses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of content <a class=\"anchor\" id=\"TOC\">\n",
    "* [Part 1: Read LowFat XML data and store in pickle](#first-bullet)\n",
    "* [part 2: Sort the nodes](#second-bullet)\n",
    "* [Part 3: Nestle1904 production from pickle input](#third-bullet)\n",
    "* [Part 4: Testing the created textfabric data](#fourth-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Read LowFat XML data and store in pickle <a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "##### [back to TOC](#TOC)\n",
    "\n",
    "This script harvests all information from the LowFat tree data (XML nodes), puts it into a Panda DataFrame and stores the result per book in a pickle file. Note: pickling (in Python) is serialising an object into a disk file (or buffer). \n",
    "\n",
    "In the context of this script, 'Leaf' refers to those node containing the Greek word as data, which happen to be the nodes without any child (hence the analogy with the leaves on the tree). These 'leafs' can also be refered to as 'terminal nodes'. Futher, Parent1 is the leaf's parent, Parent2 is Parent1's parent, etc.\n",
    "\n",
    "For a full description of the source data see document [MACULA Greek Treebank for the Nestle 1904 Greek New Testament.pdf](https://github.com/Clear-Bible/macula-greek/blob/main/doc/MACULA%20Greek%20Treebank%20for%20the%20Nestle%201904%20Greek%20New%20Testament.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: import various libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-28T02:58:14.739227Z",
     "start_time": "2022-10-28T02:57:38.766097Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import re  #regular expressions\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: initialize global data\n",
    "\n",
    "Change BaseDir, XmlDir and PklDir to match location of the datalocation and the OS used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseDir = 'C:\\\\Users\\\\tonyj\\\\my_new_Jupyter_folder\\\\Read_from_lowfat\\\\data\\\\'\n",
    "XmlDir = BaseDir+'xml\\\\'\n",
    "PklDir = BaseDir+'pkl\\\\'\n",
    "XlsxDir = BaseDir+'xlsx\\\\'\n",
    "# note: create output directory prior running this part\n",
    "\n",
    "#         key: filename,       [0]=book_long,   [1]=book_num,  [3]=book_short\n",
    "bo2book = {'01-matthew':       ['Matthew',         '1',        'Matt'],\n",
    "           '02-mark':          ['Mark',            '2',        'Mark'],\n",
    "           '03-luke':          ['Luke',            '3',        'Luke'],\n",
    "           '04-john':          ['John',            '4',        'John'],\n",
    "           '05-acts':          ['Acts',            '5',        'Acts'],\n",
    "           '06-romans':        ['Romans',          '6',        'Rom'],\n",
    "           '07-1corinthians':  ['I_Corinthians',   '7',        '1Cor'],\n",
    "           '08-2corinthians':  ['II_Corinthians',  '8',        '2Cor'],\n",
    "           '09-galatians':     ['Galatians',       '9',        'Gal'],\n",
    "           '10-ephesians':     ['Ephesians',       '10',       'Eph'],\n",
    "           '11-philippians':   ['Philippians',     '11',       'Phil'],\n",
    "           '12-colossians':    ['Colossians',      '12',       'Col'],\n",
    "           '13-1thessalonians':['I_Thessalonians', '13',       '1Thess'],\n",
    "           '14-2thessalonians':['II_Thessalonians','14',       '2Thess'],\n",
    "           '15-1timothy':      ['I_Timothy',       '15',       '1Tim'],\n",
    "           '16-2timothy':      ['II_Timothy',      '16',       '2Tim'],\n",
    "           '17-titus':         ['Titus',           '17',       'Titus'],\n",
    "           '18-philemon':      ['Philemon',        '18',       'Phlm'],\n",
    "           '19-hebrews':       ['Hebrews',         '19',       'Heb'],\n",
    "           '20-james':         ['James',           '20',       'Jas'],\n",
    "           '21-1peter':        ['I_Peter',         '21',       '1Pet'],\n",
    "           '22-2peter':        ['II_Peter',        '22',       '2Pet'],\n",
    "           '23-1john':         ['I_John',          '23',       '1John'],\n",
    "           '24-2john':         ['II_John',         '24',       '2John'],\n",
    "           '25-3john':         ['III_John',        '25',       '3John'],     \n",
    "           '26-jude':          ['Jude',            '26',       'Jude'],\n",
    "           '27-revelation':    ['Revelation',      '27',       'Rev']}\n",
    "\n",
    "bo2book = {'01-matthew':       ['Matthew',         '1',        'Matt']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 3: define Function to add parent info to each node of the XML tree\n",
    "\n",
    "In order to traverse from the 'leafs' (terminating nodes) upto the root of the tree, it is required to add information to each node pointing to the parent of each node.\n",
    "\n",
    "(concept taken from https://stackoverflow.com/questions/2170610/access-elementtree-node-parent-node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addParentInfo(et):\n",
    "    for child in et:\n",
    "        child.attrib['parent'] = et\n",
    "        addParentInfo(child)\n",
    "\n",
    "def getParent(et):\n",
    "    if 'parent' in et.attrib:\n",
    "        return et.attrib['parent']\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: read and process the XML data and store panda dataframe in pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Matthew at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\01-matthew.xml\n",
      "......................................................................................................................................................................................\n",
      "Found  18299  items in  337.3681836128235 seconds\n",
      "\n",
      "Processing Mark at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\02-mark.xml\n",
      "................................................................................................................\n",
      "Found  11277  items in  144.04719877243042 seconds\n",
      "\n",
      "Processing Luke at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\03-luke.xml\n",
      "..................................................................................................................................................................................................\n",
      "Found  19456  items in  1501.197922706604 seconds\n",
      "\n",
      "Processing John at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\04-john.xml\n",
      "............................................................................................................................................................\n",
      "Found  15643  items in  237.1071105003357 seconds\n",
      "\n",
      "Processing Acts at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\05-acts.xml\n",
      ".......................................................................................................................................................................................\n",
      "Found  18393  items in  384.3644151687622 seconds\n",
      "\n",
      "Processing Romans at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\06-romans.xml\n",
      ".......................................................................\n",
      "Found  7100  items in  71.03568935394287 seconds\n",
      "\n",
      "Processing I_Corinthians at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\07-1corinthians.xml\n",
      "....................................................................\n",
      "Found  6820  items in  58.47511959075928 seconds\n",
      "\n",
      "Processing II_Corinthians at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\08-2corinthians.xml\n",
      "............................................\n",
      "Found  4469  items in  31.848721027374268 seconds\n",
      "\n",
      "Processing Galatians at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\09-galatians.xml\n",
      "......................\n",
      "Found  2228  items in  13.850211143493652 seconds\n",
      "\n",
      "Processing Ephesians at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\10-ephesians.xml\n",
      "........................\n",
      "Found  2419  items in  17.529520511627197 seconds\n",
      "\n",
      "Processing Philippians at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\11-philippians.xml\n",
      "................\n",
      "Found  1630  items in  9.271572589874268 seconds\n",
      "\n",
      "Processing Colossians at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\12-colossians.xml\n",
      "...............\n",
      "Found  1575  items in  10.389309883117676 seconds\n",
      "\n",
      "Processing I_Thessalonians at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\13-1thessalonians.xml\n",
      "..............\n",
      "Found  1473  items in  8.413437604904175 seconds\n",
      "\n",
      "Processing II_Thessalonians at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\14-2thessalonians.xml\n",
      "........\n",
      "Found  822  items in  4.284915447235107 seconds\n",
      "\n",
      "Processing I_Timothy at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\15-1timothy.xml\n",
      "...............\n",
      "Found  1588  items in  10.419771671295166 seconds\n",
      "\n",
      "Processing II_Timothy at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\16-2timothy.xml\n",
      "............\n",
      "Found  1237  items in  7.126454591751099 seconds\n",
      "\n",
      "Processing Titus at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\17-titus.xml\n",
      "......\n",
      "Found  658  items in  3.1472580432891846 seconds\n",
      "\n",
      "Processing Philemon at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\18-philemon.xml\n",
      "...\n",
      "Found  335  items in  1.3175146579742432 seconds\n",
      "\n",
      "Processing Hebrews at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\19-hebrews.xml\n",
      ".................................................\n",
      "Found  4955  items in  44.31139326095581 seconds\n",
      "\n",
      "Processing James at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\20-james.xml\n",
      ".................\n",
      "Found  1739  items in  8.570415496826172 seconds\n",
      "\n",
      "Processing I_Peter at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\21-1peter.xml\n",
      "................\n",
      "Found  1676  items in  10.489561557769775 seconds\n",
      "\n",
      "Processing II_Peter at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\22-2peter.xml\n",
      "..........\n",
      "Found  1098  items in  6.005697250366211 seconds\n",
      "\n",
      "Processing I_John at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\23-1john.xml\n",
      ".....................\n",
      "Found  2136  items in  10.843079566955566 seconds\n",
      "\n",
      "Processing II_John at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\24-2john.xml\n",
      "..\n",
      "Found  245  items in  0.9535031318664551 seconds\n",
      "\n",
      "Processing III_John at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\25-3john.xml\n",
      "..\n",
      "Found  219  items in  1.0913233757019043 seconds\n",
      "\n",
      "Processing Jude at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\26-jude.xml\n",
      "....\n",
      "Found  457  items in  1.8929190635681152 seconds\n",
      "\n",
      "Processing Revelation at C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\xml\\27-revelation.xml\n",
      "..................................................................................................\n",
      "Found  9832  items in  125.92533278465271 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set some globals\n",
    "monad=1\n",
    "CollectedItems= 0\n",
    "\n",
    "# process books in order\n",
    "for bo, bookinfo in bo2book.items():\n",
    "  CollectedItems=0\n",
    "  SentenceNumber=0\n",
    "  WordGroupNumber=0\n",
    "  full_df=pd.DataFrame({})\n",
    "  book_long=bookinfo[0]\n",
    "  booknum=bookinfo[1]\n",
    "  book_short=bookinfo[2]\n",
    "  InputFile = os.path.join(XmlDir, f'{bo}.xml')\n",
    "  OutputFile = os.path.join(PklDir, f'{bo}.pkl')\n",
    "  print(f'Processing {book_long} at {InputFile}')\n",
    "\n",
    "  # send xml document to parsing process\n",
    "  tree = ET.parse(InputFile)\n",
    "  # Now add all the parent info to the nodes in the xtree [important!]\n",
    "  addParentInfo(tree.getroot())\n",
    "  start_time = time.time()\n",
    "    \n",
    "  # walk over all the XML data\n",
    "  for elem in tree.iter():\n",
    "    if elem.tag == 'sentence':\n",
    "        # add running number to 'sentence' tags\n",
    "        SentenceNumber+=1\n",
    "        elem.set('SN', SentenceNumber)\n",
    "    if elem.tag == 'wg':\n",
    "        # add running number to 'wg' tags\n",
    "        WordGroupNumber+=1\n",
    "        elem.set('WGN', WordGroupNumber)\n",
    "    if elem.tag == 'w':\n",
    "        # all nodes containing words are tagged with 'w'\n",
    "     \n",
    "        # show  progress on screen\n",
    "        CollectedItems+=1\n",
    "        if (CollectedItems%100==0): print (\".\",end='')\n",
    "        \n",
    "        #Leafref will contain list with book, chapter verse and wordnumber\n",
    "        Leafref = re.sub(r'[!: ]',\" \", elem.attrib.get('ref')).split()\n",
    "        \n",
    "        #push value for monad to element tree \n",
    "        elem.set('monad', monad)\n",
    "        monad+=1\n",
    "        \n",
    "        # add some important computed data to the leaf\n",
    "        elem.set('LeafName', elem.tag)\n",
    "        elem.set('word', elem.text)\n",
    "        elem.set('book_long', book_long)\n",
    "        elem.set('booknum', int(booknum))\n",
    "        elem.set('book_short', book_short)\n",
    "        elem.set('chapter', int(Leafref[1]))\n",
    "        elem.set('verse', int(Leafref[2]))\n",
    "       \n",
    "        # folling code will trace down parents upto the tree and store found attributes\n",
    "        parentnode=getParent(elem)\n",
    "        index=0\n",
    "        while (parentnode):\n",
    "           index+=1\n",
    "           elem.set('Parent{}Name'.format(index),      parentnode.tag)\n",
    "           elem.set('Parent{}Type'.format(index),      parentnode.attrib.get('type'))\n",
    "           elem.set('Parent{}Appos'.format(index),     parentnode.attrib.get('appositioncontainer'))\n",
    "           elem.set('Parent{}Class'.format(index),     parentnode.attrib.get('class'))\n",
    "           elem.set('Parent{}Rule'.format(index),      parentnode.attrib.get('rule'))\n",
    "           elem.set('Parent{}Role'.format(index),      parentnode.attrib.get('role'))\n",
    "           elem.set('Parent{}Cltype'.format(index),    parentnode.attrib.get('cltype'))\n",
    "           elem.set('Parent{}Unit'.format(index),      parentnode.attrib.get('unit'))\n",
    "           elem.set('Parent{}Junction'.format(index),  parentnode.attrib.get('junction'))\n",
    "           elem.set('Parent{}SN'.format(index),        parentnode.attrib.get('SN'))\n",
    "           elem.set('Parent{}WGN'.format(index),       parentnode.attrib.get('WGN'))\n",
    "           currentnode=parentnode\n",
    "           parentnode=getParent(currentnode)      \n",
    "        elem.set('parents', int(index))\n",
    "        \n",
    "        #this will push all elements found in the tree into a DataFrame\n",
    "        df=pd.DataFrame(elem.attrib, index={monad})\n",
    "        full_df=pd.concat([full_df,df])\n",
    "        \n",
    "  #store the resulting DataFrame per book into a pickle file for further processing\n",
    "  df = df.convert_dtypes(convert_string=True)\n",
    "    \n",
    "  # sort by s=id\n",
    "  sortkey='{http://www.w3.org/XML/1998/namespace}id'\n",
    "  full_df.rename(columns={sortkey: 'id'}, inplace=True)\n",
    "  full_df.sort_values(by=['id'])\n",
    "\n",
    "  output = open(r\"{}\".format(OutputFile), 'wb')\n",
    "  pickle.dump(full_df, output)\n",
    "  output.close()\n",
    "  print(\"\\nFound \",CollectedItems, \" items in  %s seconds\\n\" % (time.time() - start_time))  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just dump some things to test the result\n",
    "\n",
    "\n",
    "for bo in bo2book:\n",
    "        '''\n",
    "        load all data into a dataframe\n",
    "        process books in order (bookinfo is a list!)\n",
    "        '''   \n",
    "        InputFile = os.path.join(PklDir, f'{bo}.pkl')\n",
    "       \n",
    "        print(f'\\tloading {InputFile}...')\n",
    "        pkl_file = open(InputFile, 'rb')\n",
    "        df = pickle.load(pkl_file)\n",
    "        pkl_file.close()\n",
    "   \n",
    "        # not sure if this is needed\n",
    "        # fill dictionary of column names for this book \n",
    "        IndexDict = {}             # init an empty dictionary\n",
    "        ItemsInRow=1\n",
    "        for itemname in df.columns.to_list():\n",
    "            IndexDict.update({'i_{}'.format(itemname): ItemsInRow})\n",
    "            print (itemname)\n",
    "            ItemsInRow+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "## Part 3: Nestle1904 Text-Fabric production from pickle input <a class=\"anchor\" id=\"second-bullet\"></a>\n",
    "##### [back to TOC](#TOC)\n",
    "\n",
    "This script creates the Text-Fabric files by recursive calling the TF walker function.\n",
    "API info: https://annotation.github.io/text-fabric/tf/convert/walker.html\n",
    "\n",
    "The pickle files created by step 1 are stored on Github location T.B.D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load libraries and initialize some data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-28T03:01:34.810259Z",
     "start_time": "2022-10-28T03:01:25.745112Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import gc\n",
    "from tf.fabric import Fabric\n",
    "from tf.convert.walker import CV\n",
    "from tf.parameters import VERSION\n",
    "from datetime import date\n",
    "import pickle\n",
    "\n",
    "BaseDir = 'C:\\\\Users\\\\tonyj\\\\my_new_Jupyter_folder\\\\Read_from_lowfat\\\\data\\\\'\n",
    "XmlDir = BaseDir+'xml\\\\'\n",
    "PklDir = BaseDir+'pkl\\\\'\n",
    "XlsxDir = BaseDir+'xlsx\\\\'\n",
    "\n",
    "#         key: filename,       [0]=book_long,   [1]=book_num,  [3]=book_short\n",
    "bo2book = {'01-matthew':       ['Matthew',         '1',        'Matt'],\n",
    "           '02-mark':          ['Mark',            '2',        'Mark'],\n",
    "           '03-luke':          ['Luke',            '3',        'Luke'],\n",
    "           '04-john':          ['John',            '4',        'John'],\n",
    "           '05-acts':          ['Acts',            '5',        'Acts'],\n",
    "           '06-romans':        ['Romans',          '6',        'Rom'],\n",
    "           '07-1corinthians':  ['I_Corinthians',   '7',        '1Cor'],\n",
    "           '08-2corinthians':  ['II_Corinthians',  '8',        '2Cor'],\n",
    "           '09-galatians':     ['Galatians',       '9',        'Gal'],\n",
    "           '10-ephesians':     ['Ephesians',       '10',       'Eph'],\n",
    "           '11-philippians':   ['Philippians',     '11',       'Phil'],\n",
    "           '12-colossians':    ['Colossians',      '12',       'Col'],\n",
    "           '13-1thessalonians':['I_Thessalonians', '13',       '1Thess'],\n",
    "           '14-2thessalonians':['II_Thessalonians','14',       '2Thess'],\n",
    "           '15-1timothy':      ['I_Timothy',       '15',       '1Tim'],\n",
    "           '16-2timothy':      ['II_Timothy',      '16',       '2Tim'],\n",
    "           '17-titus':         ['Titus',           '17',       'Titus'],\n",
    "           '18-philemon':      ['Philemon',        '18',       'Phlm'],\n",
    "           '19-hebrews':       ['Hebrews',         '19',       'Heb'],\n",
    "           '20-james':         ['James',           '20',       'Jas'],\n",
    "           '21-1peter':        ['I_Peter',         '21',       '1Pet'],\n",
    "           '22-2peter':        ['II_Peter',        '22',       '2Pet'],\n",
    "           '23-1john':         ['I_John',          '23',       '1John'],\n",
    "           '24-2john':         ['II_John',         '24',       '2John'],\n",
    "           '25-3john':         ['III_John',        '25',       '3John'],     \n",
    "           '26-jude':          ['Jude',            '26',       'Jude'],\n",
    "           '27-revelation':    ['Revelation',      '27',       'Rev']}\n",
    "\n",
    "bo2book_ = {'26-jude':          ['Jude',            '26',       'Jude']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: export to Excel for investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test: sorting the data\n",
    "import openpyxl\n",
    "import pickle\n",
    "\n",
    "#if True:\n",
    "for bo in bo2book:\n",
    "        '''\n",
    "        load all data into a dataframe\n",
    "        process books in order (bookinfo is a list!)\n",
    "        '''   \n",
    "        InputFile = os.path.join(PklDir, f'{bo}.pkl')\n",
    "        #InputFile = os.path.join(PklDir, '01-matthew.pkl')\n",
    "       \n",
    "        print(f'\\tloading {InputFile}...')\n",
    "        pkl_file = open(InputFile, 'rb')\n",
    "        df = pickle.load(pkl_file)\n",
    "        pkl_file.close()\n",
    "   \n",
    "        # not sure if this is needed\n",
    "        # fill dictionary of column names for this book \n",
    "        IndexDict = {}             # init an empty dictionary\n",
    "        ItemsInRow=1\n",
    "        for itemname in df.columns.to_list():\n",
    "            IndexDict.update({'i_{}'.format(itemname): ItemsInRow})\n",
    "            ItemsInRow+=1\n",
    "            #print(itemname)\n",
    "        \n",
    "        # sort by id\n",
    "        #print(df)\n",
    "        df_sorted=df.sort_values(by=['id'])\n",
    "        df_sorted.to_excel(os.path.join(XlsxDir, f'{bo}.xlsx'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 Running the TF walker function\n",
    "\n",
    "API info: https://annotation.github.io/text-fabric/tf/convert/walker.html\n",
    "\n",
    "The logic of interpreting the data is included in the director function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 11.2.3\n",
      "51 features found and 0 ignored\n",
      "  0.00s Importing data from walking through the source ...\n",
      "   |     0.00s Preparing metadata... \n",
      "   |   SECTION   TYPES:    book, chapter, verse\n",
      "   |   SECTION   FEATURES: book, chapter, verse\n",
      "   |   STRUCTURE TYPES:    book, chapter, verse\n",
      "   |   STRUCTURE FEATURES: book, chapter, verse\n",
      "   |   TEXT      FEATURES:\n",
      "   |      |   text-orig-full       after, word\n",
      "   |     0.00s OK\n",
      "   |     0.00s Following director... \n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\01-matthew.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\02-mark.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\03-luke.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\04-john.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\05-acts.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\06-romans.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\07-1corinthians.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\08-2corinthians.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\09-galatians.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\10-ephesians.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\11-philippians.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\12-colossians.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\13-1thessalonians.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\14-2thessalonians.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\15-1timothy.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\16-2timothy.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\17-titus.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\18-philemon.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\19-hebrews.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\20-james.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\21-1peter.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\22-2peter.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\23-1john.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\24-2john.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\25-3john.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\26-jude.pkl...\n",
      "\tWe are loading C:\\Users\\tonyj\\my_new_Jupyter_folder\\Read_from_lowfat\\data\\pkl\\27-revelation.pkl...\n",
      "   |       52s \"edge\" actions: 0\n",
      "   |       52s \"feature\" actions: 267471\n",
      "   |       52s \"node\" actions: 129692\n",
      "   |       52s \"resume\" actions: 9629\n",
      "   |       52s \"slot\" actions: 137779\n",
      "   |       52s \"terminate\" actions: 277227\n",
      "   |         27 x \"book\" node \n",
      "   |        260 x \"chapter\" node \n",
      "   |       8011 x \"sentence\" node \n",
      "   |       7943 x \"verse\" node \n",
      "   |     113451 x \"wg\" node \n",
      "   |     137779 x \"word\" node  = slot type\n",
      "   |     267471 nodes of all types\n",
      "   |       52s OK\n",
      "   |     0.00s checking for nodes and edges ... \n",
      "   |     0.00s OK\n",
      "   |     0.00s checking (section) features ... \n",
      "   |     0.20s OK\n",
      "   |     0.00s reordering nodes ...\n",
      "   |     0.04s Sorting 27 nodes of type \"book\"\n",
      "   |     0.05s Sorting 260 nodes of type \"chapter\"\n",
      "   |     0.06s Sorting 8011 nodes of type \"sentence\"\n",
      "   |     0.09s Sorting 7943 nodes of type \"verse\"\n",
      "   |     0.11s Sorting 113451 nodes of type \"wg\"\n",
      "   |     0.24s Max node = 267471\n",
      "   |     0.24s OK\n",
      "   |     0.00s reassigning feature values ...\n",
      "   |      |     0.00s node feature \"after\" with 137779 nodes\n",
      "   |      |     0.04s node feature \"appos\" with 113451 nodes\n",
      "   |      |     0.09s node feature \"book\" with 27 nodes\n",
      "   |      |     0.09s node feature \"book_long\" with 137779 nodes\n",
      "   |      |     0.14s node feature \"booknumber\" with 137806 nodes\n",
      "   |      |     0.19s node feature \"bookshort\" with 137806 nodes\n",
      "   |      |     0.24s node feature \"case\" with 137779 nodes\n",
      "   |      |     0.29s node feature \"chapter\" with 153939 nodes\n",
      "   |      |     0.35s node feature \"clausetype\" with 113451 nodes\n",
      "   |      |     0.40s node feature \"degree\" with 137779 nodes\n",
      "   |      |     0.45s node feature \"gloss\" with 137779 nodes\n",
      "   |      |     0.50s node feature \"gn\" with 137779 nodes\n",
      "   |      |     0.56s node feature \"id\" with 137779 nodes\n",
      "   |      |     0.61s node feature \"junction\" with 113451 nodes\n",
      "   |      |     0.65s node feature \"lemma\" with 137779 nodes\n",
      "   |      |     0.70s node feature \"lex_dom\" with 137779 nodes\n",
      "   |      |     0.76s node feature \"ln\" with 137779 nodes\n",
      "   |      |     0.81s node feature \"monad\" with 137779 nodes\n",
      "   |      |     0.86s node feature \"mood\" with 137779 nodes\n",
      "   |      |     0.91s node feature \"morph\" with 137779 nodes\n",
      "   |      |     0.96s node feature \"nodeID\" with 137779 nodes\n",
      "   |      |     1.02s node feature \"normalized\" with 137779 nodes\n",
      "   |      |     1.07s node feature \"nu\" with 137779 nodes\n",
      "   |      |     1.13s node feature \"number\" with 137779 nodes\n",
      "   |      |     1.18s node feature \"orig_order\" with 137779 nodes\n",
      "   |      |     1.23s node feature \"person\" with 137779 nodes\n",
      "   |      |     1.28s node feature \"ref\" with 137779 nodes\n",
      "   |      |     1.34s node feature \"reference\" with 137779 nodes\n",
      "   |      |     1.39s node feature \"rule\" with 113451 nodes\n",
      "   |      |     1.45s node feature \"sentence\" with 137779 nodes\n",
      "   |      |     1.50s node feature \"sp\" with 137779 nodes\n",
      "   |      |     1.56s node feature \"sp_full\" with 137779 nodes\n",
      "   |      |     1.61s node feature \"strongs\" with 137779 nodes\n",
      "   |      |     1.66s node feature \"subj_ref\" with 137779 nodes\n",
      "   |      |     1.71s node feature \"tense\" with 137779 nodes\n",
      "   |      |     1.76s node feature \"type\" with 137779 nodes\n",
      "   |      |     1.81s node feature \"unicode\" with 137779 nodes\n",
      "   |      |     1.87s node feature \"verse\" with 153733 nodes\n",
      "   |      |     1.93s node feature \"voice\" with 137779 nodes\n",
      "   |      |     1.98s node feature \"wgclass\" with 113451 nodes\n",
      "   |      |     2.03s node feature \"wgrole\" with 113451 nodes\n",
      "   |      |     2.08s node feature \"wgrolelong\" with 113451 nodes\n",
      "   |      |     2.12s node feature \"wgtype\" with 113451 nodes\n",
      "   |      |     2.16s node feature \"word\" with 137779 nodes\n",
      "   |      |     2.22s node feature \"wordgroup\" with 113451 nodes\n",
      "   |      |     2.26s node feature \"wordrole\" with 137779 nodes\n",
      "   |      |     2.31s node feature \"wordrolelong\" with 137779 nodes\n",
      "   |     2.45s OK\n",
      "  0.00s Exporting 48 node and 1 edge and 1 config features to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data/:\n",
      "  0.00s VALIDATING oslots feature\n",
      "  0.02s VALIDATING oslots feature\n",
      "  0.02s maxSlot=     137779\n",
      "  0.02s maxNode=     267471\n",
      "  0.04s OK: oslots is valid\n",
      "   |     0.14s T after                to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.12s T appos                to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.01s T book                 to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.14s T book_long            to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.13s T booknumber           to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.14s T bookshort            to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.16s T case                 to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.15s T chapter              to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.11s T clausetype           to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.14s T degree               to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.15s T gloss                to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.15s T gn                   to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.14s T id                   to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.11s T junction             to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.17s T lemma                to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.15s T lex_dom              to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.14s T ln                   to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.14s T monad                to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.14s T mood                 to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.15s T morph                to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.15s T nodeID               to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.17s T normalized           to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.15s T nu                   to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.15s T number               to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.15s T orig_order           to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.07s T otype                to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.15s T person               to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.15s T ref                  to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.15s T reference            to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.13s T rule                 to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.16s T sentence             to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.14s T sp                   to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.14s T sp_full              to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.15s T strongs              to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.14s T subj_ref             to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.14s T tense                to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.14s T type                 to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.17s T unicode              to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.15s T verse                to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.14s T voice                to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.13s T wgclass              to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.12s T wgrole               to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.11s T wgrolelong           to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.11s T wgtype               to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.17s T word                 to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.11s T wordgroup            to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.14s T wordrole             to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.17s T wordrolelong         to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.36s T oslots               to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "   |     0.00s M otext                to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data\n",
      "  7.06s Exported 48 node features and 1 edge features and 1 config features to C:/Users/tonyj/my_new_Jupyter_folder/Read_from_lowfat/data/\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "TF = Fabric(locations=BaseDir, silent=False)\n",
    "cv = CV(TF)\n",
    "version = \"0.1.6 (moved all phrases and claused to wordgroup nodes)\"\n",
    "\n",
    "\n",
    "def sanitize(input):\n",
    "    if isinstance(input, float): return ''\n",
    "    if isinstance(input, type(None)): return ''\n",
    "    else: return (input)\n",
    "    \n",
    "def ExpandRole(input):\n",
    "    if input==\"adv\": return 'Adverbial'\n",
    "    if input==\"io\":  return 'Indirect Object'\n",
    "    if input==\"o\":   return 'Object'\n",
    "    if input==\"o2\":  return 'Second Object'\n",
    "    if input==\"s\":   return 'Subject'\n",
    "    if input==\"p\":   return 'Predicate'\n",
    "    if input==\"v\":   return 'Verbal'\n",
    "    if input==\"vc\":  return 'Verbal Copula'\n",
    "    return ''\n",
    "\n",
    "# Expantion of part of speach labels. See also the description in \n",
    "# \"MACULA Greek Treebank for the Nestle 1904 Greek New Testament.pdf\" page 6&7\n",
    "# (2.2. Syntactic Categories at Word Level: Part of Speech Labels)\n",
    "def ExpandSP(input):\n",
    "    if input=='adj':  return 'adjective'\n",
    "    if input=='conj': return 'conjunction'\n",
    "    if input=='det':  return 'determiner' \n",
    "    if input=='intj': return 'interjection' \n",
    "    if input=='noun': return 'noun' \n",
    "    if input=='num':  return 'numeral' \n",
    "    if input=='prep': return 'preposition' \n",
    "    if input=='ptcl': return 'particle' \n",
    "    if input=='pron': return 'pronoun' \n",
    "    if input=='verb': return 'verb' \n",
    "    return input\n",
    "\n",
    "\n",
    "def director(cv):\n",
    "    \n",
    "    NoneType = type(None)      # needed as tool to validate certain data\n",
    "    IndexDict = {}             # init an empty dictionary\n",
    "    \n",
    "    Arrays2Dump=200\n",
    "    DumpedArrays=0\n",
    "    WordGroupDict={}    # init a dummy dictionary\n",
    "    PrevWordGroupSet = WordGroupSet = []\n",
    "    PrevWordGroupList = WordGroupList = []\n",
    "    RootWordGroup = 0\n",
    "    WordNumber=FoundWords=WordGroupTrack=0\n",
    "    DummyWGN=200000  # this number is arbitrary but should be high enough not to clash with 'real' WG numbers\n",
    "    \n",
    "    '''\n",
    "    process books in order (bookinfo is a list!)\n",
    "    '''  \n",
    "    for bo,bookinfo in bo2book.items():\n",
    "        \n",
    "\n",
    "        Book        = bookinfo[0]  \n",
    "        BookNumber  = int(bookinfo[1])\n",
    "        BookShort   = bookinfo[2]\n",
    "        BookLoc     = os.path.join(PklDir, f'{bo}.pkl') \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        load  data for this book into a dataframe. Make sure wordorder is correct\n",
    "        '''  \n",
    "        print(f'\\tWe are loading {BookLoc}...')\n",
    "        pkl_file = open(BookLoc, 'rb')\n",
    "        df_unsorted = pickle.load(pkl_file)\n",
    "        pkl_file.close()\n",
    "        df=df_unsorted.sort_values(by=['id'])\n",
    " \n",
    "        \n",
    "        '''\n",
    "        set up nodes for new book\n",
    "        ''' \n",
    "        ThisBookPointer = cv.node('book')\n",
    "        cv.feature(ThisBookPointer, book=Book, booknumber=BookNumber, bookshort=BookShort)\n",
    "        \n",
    "        ThisChapterPointer = cv.node('chapter')\n",
    "        cv.feature(ThisChapterPointer, chapter=1)\n",
    "        PreviousChapter=1\n",
    "        \n",
    "        ThisVersePointer = cv.node('verse')\n",
    "        cv.feature(ThisVersePointer, verse=1)\n",
    "        PreviousVerse=1\n",
    "        \n",
    "        ThisSentencePointer = cv.node('sentence')\n",
    "        cv.feature(ThisSentencePointer, verse=1)\n",
    "        PreviousSentence=1                \n",
    "\n",
    "\n",
    "        '''\n",
    "        fill dictionary of column names for this book \n",
    "        sort to ensure proper wordorder\n",
    "        '''\n",
    "        ItemsInRow=1\n",
    "        for itemname in df.columns.to_list():\n",
    "            IndexDict.update({'i_{}'.format(itemname): ItemsInRow})\n",
    "            ItemsInRow+=1\n",
    "        df.sort_values(by=['id'])\n",
    "        \n",
    "\n",
    "        '''\n",
    "        Walks through the texts and trigger slot and node creation events.\n",
    "        iterate through words and construct objects\n",
    "        '''\n",
    "        for row in df.itertuples():\n",
    "            WordNumber += 1\n",
    "            FoundWords +=1\n",
    "            \n",
    "          \n",
    "            '''\n",
    "            First act upon changes in sentences, verse and chapter \n",
    "            '''   \n",
    "            NumberOfParents = row[IndexDict.get(\"i_parents\")]\n",
    "            ThisSentence=int(row[IndexDict.get(\"i_Parent{}SN\".format(NumberOfParents-1))])\n",
    "            ThisVerse = sanitize(row[IndexDict.get(\"i_verse\")])\n",
    "            ThisChapter = sanitize(row[IndexDict.get(\"i_chapter\")])\n",
    "            if (ThisSentence!=PreviousSentence):\n",
    "                #cv.feature(ThisSentencePointer, statdata?)\n",
    "                cv.terminate(ThisSentencePointer)\n",
    "                \n",
    "            if (ThisVerse!=PreviousVerse):\n",
    "                #cv.feature(ThisVersePointer, statdata?)\n",
    "                cv.terminate(ThisVersePointer)\n",
    "\n",
    "            if (ThisChapter!=PreviousChapter):\n",
    "                #cv.feature(ThisChapterPointer, statdata?)\n",
    "                cv.terminate(ThisChapterPointer)\n",
    "                PreviousChapter = ThisChapter\n",
    "                ThisChapterPointer = cv.node('chapter')\n",
    "                cv.feature(ThisChapterPointer, chapter=ThisChapter)\n",
    "                \n",
    "            if (ThisVerse!=PreviousVerse):\n",
    "                PreviousVerse = ThisVerse  \n",
    "                ThisVersePointer = cv.node('verse')\n",
    "                cv.feature(ThisVersePointer, verse=ThisVerse, chapter=ThisChapter)\n",
    "                \n",
    "            if (ThisSentence!=PreviousSentence):\n",
    "                PreviousSentence=ThisSentence\n",
    "                ThisSentencePointer = cv.node('sentence')\n",
    "                cv.feature(ThisSentencePointer, verse=ThisVerse, chapter=ThisChapter)       \n",
    "\n",
    "        \n",
    "                    \n",
    "            # get number of parent nodes (this differs per word)\n",
    "            # decoding the WordGroup data\n",
    "            PrevWordGroupList=WordGroupList\n",
    "            WordGroupList=[]  # stores current active WordGroup numbers\n",
    "\n",
    "            for i in range(NumberOfParents-2,0,-1): # reversed itteration\n",
    "                _WGN=row[IndexDict.get(\"i_Parent{}WGN\".format(i))]\n",
    "                if isinstance(_WGN, type(None)): \n",
    "                    # handling conditions where XML data has <error role=\"err_clause-complex-met-no-conditionsClCl2\"> e.g. Acts 26:12\n",
    "                    # to recover, we need to create a dummy WG with a sufficient high WGN so it can never match any real WGN. \n",
    "                    WGN=DummyWGN\n",
    "                else:\n",
    "                    WGN=int(_WGN)\n",
    "                if WGN!='':\n",
    "                     WordGroupList.append(WGN)\n",
    "                     WordGroupDict[(WGN,0)]=WGN\n",
    "                     WordGroupDict[(WGN,1)]=sanitize(row[IndexDict.get(\"i_Parent{}Rule\".format(i))])\n",
    "                     WordGroupDict[(WGN,2)]=sanitize(row[IndexDict.get(\"i_Parent{}Cltype\".format(i))])\n",
    "                     WordGroupDict[(WGN,3)]=sanitize(row[IndexDict.get(\"i_Parent{}Junction\".format(i))])\n",
    "                     WordGroupDict[(WGN,6)]=sanitize(row[IndexDict.get(\"i_Parent{}Class\".format(i))])\n",
    "                     WordGroupDict[(WGN,7)]=sanitize(row[IndexDict.get(\"i_Parent{}Role\".format(i))])\n",
    "                     WordGroupDict[(WGN,8)]=sanitize(row[IndexDict.get(\"i_Parent{}Type\".format(i))])\n",
    "                     WordGroupDict[(WGN,9)]=sanitize(row[IndexDict.get(\"i_Parent{}Appos\".format(i))])           \n",
    "            if not PrevWordGroupList==WordGroupList:\n",
    "                if RootWordGroup != WordGroupList[0]:\n",
    "                    RootWordGroup = WordGroupList[0]\n",
    "                    SuspendableWordGoupList = []\n",
    "                    # we have a new sentence. rebuild suspendable wordgroup list\n",
    "                    # some cleaning of data may be added here to save on memmory... \n",
    "                    #for k in range(6): del WordGroupDict[item,k]\n",
    "                for item in reversed(PrevWordGroupList):\n",
    "                    if (item not in WordGroupList):\n",
    "                         # CLOSE/SUSPEND CASE\n",
    "                         SuspendableWordGoupList.append(item)\n",
    "                         cv.terminate(WordGroupDict[item,4])\n",
    "                for item in WordGroupList:\n",
    "                    if (item not in PrevWordGroupList):\n",
    "                        if (item in SuspendableWordGoupList):\n",
    "                              # RESUME CASE\n",
    "                              #print ('\\n resume: '+str(item),end=' ')\n",
    "                              cv.resume(WordGroupDict[(item,4)])\n",
    "                        else:\n",
    "                              # CREATE CASE\n",
    "                              #print ('\\n create: '+str(item),end=' ')\n",
    "                              WordGroupDict[(item,4)]=cv.node('wg')\n",
    "                              WordGroupDict[(item,5)]=WordGroupTrack\n",
    "                              WordGroupTrack += 1\n",
    "                              cv.feature(WordGroupDict[(item,4)], wordgroup=WordGroupDict[(item,0)], junction=WordGroupDict[(item,3)], \n",
    "                                         clausetype=WordGroupDict[(item,2)], rule=WordGroupDict[(item,1)], wgclass=WordGroupDict[(item,6)], \n",
    "                                         wgrole=WordGroupDict[(item,7)],wgrolelong=ExpandRole(WordGroupDict[(item,7)]),\n",
    "                                         wgtype=WordGroupDict[(item,8)],appos=WordGroupDict[(item,8)])\n",
    "\n",
    "               \n",
    "     \n",
    "            # determine syntactic categories of words or wordgroup. See also the description in \n",
    "            # \"MACULA Greek Treebank for the Nestle 1904 Greek New Testament.pdf\" page 5&6\n",
    "            # (section 2.4 Syntactic Categories at Clause Level)\n",
    "            # word level roles:\n",
    "            Role=row[IndexDict.get(\"i_role\")]\n",
    "            ValidRoles=[\"adv\",\"io\",\"o\",\"o2\",\"s\",\"p\",\"v\",\"vc\"]\n",
    "            if isinstance (Role,str) and Role in ValidRoles: \n",
    "                WordRole=Role\n",
    "                WordRoleLong=ExpandRole(WordRole)\n",
    "            else:\n",
    "                WordRole=WordRoleLong=''\n",
    "\n",
    "\n",
    "                \n",
    "            '''\n",
    "            -- create word nodes --\n",
    "            '''   \n",
    "                \n",
    "       \n",
    "    \n",
    "            # determine syntactic categories at word level. \n",
    "            PartOfSpeech=sanitize(row[IndexDict.get(\"i_class\")])\n",
    "            PartOfSpeechFull=ExpandSP(PartOfSpeech)\n",
    "                    \n",
    "            # some attributes are not present inside some (small) books. The following is to prevent exceptions.\n",
    "            degree='' \n",
    "            if 'i_degree' in IndexDict: \n",
    "                   degree=sanitize(row[IndexDict.get(\"i_degree\")]) \n",
    "            subjref=''\n",
    "            if 'i_subjref' in IndexDict:\n",
    "                   subjref=sanitize(row[IndexDict.get(\"i_subjref\")]) \n",
    "\n",
    "                    \n",
    "            # create the word slots\n",
    "            this_word = cv.slot()\n",
    "            cv.feature(this_word, \n",
    "                    after=         sanitize(row[IndexDict.get(\"i_after\")]),\n",
    "                    id=            sanitize(row[IndexDict.get(\"i_id\")]),\n",
    "                    unicode=       sanitize(row[IndexDict.get(\"i_unicode\")]),\n",
    "                    word=          sanitize(row[IndexDict.get(\"i_word\")]),\n",
    "                    monad=         sanitize(row[IndexDict.get(\"i_monad\")]),\n",
    "                    orig_order=    FoundWords,\n",
    "                    book_long=     sanitize(row[IndexDict.get(\"i_book_long\")]),\n",
    "                    booknumber=    BookNumber,\n",
    "                    bookshort=     sanitize(row[IndexDict.get(\"i_book_short\")]),\n",
    "                    chapter=       ThisChapter,\n",
    "                    ref=           sanitize(row[IndexDict.get(\"i_ref\")]),\n",
    "                    sp=            PartOfSpeech,\n",
    "                    sp_full=       PartOfSpeechFull,\n",
    "                    verse=         ThisVerse,\n",
    "                    sentence=      ThisSentence,\n",
    "                    normalized=    sanitize(row[IndexDict.get(\"i_normalized\")]),\n",
    "                    morph=         sanitize(row[IndexDict.get(\"i_morph\")]),\n",
    "                    strongs=       sanitize(row[IndexDict.get(\"i_strong\")]),\n",
    "                    lex_dom=       sanitize(row[IndexDict.get(\"i_domain\")]),\n",
    "                    ln=            sanitize(row[IndexDict.get(\"i_ln\")]),\n",
    "                    gloss=         sanitize(row[IndexDict.get(\"i_gloss\")]),\n",
    "                    gn=            sanitize(row[IndexDict.get(\"i_gender\")]),\n",
    "                    nu=            sanitize(row[IndexDict.get(\"i_number\")]),\n",
    "                    case=          sanitize(row[IndexDict.get(\"i_case\")]),\n",
    "                    lemma=         sanitize(row[IndexDict.get(\"i_lemma\")]),\n",
    "                    person=        sanitize(row[IndexDict.get(\"i_person\")]),\n",
    "                    mood=          sanitize(row[IndexDict.get(\"i_mood\")]),\n",
    "                    tense=         sanitize(row[IndexDict.get(\"i_tense\")]),\n",
    "                    number=        sanitize(row[IndexDict.get(\"i_number\")]),\n",
    "                    voice=         sanitize(row[IndexDict.get(\"i_voice\")]),\n",
    "                    degree=        degree,\n",
    "                    type=          sanitize(row[IndexDict.get(\"i_type\")]),\n",
    "                    reference=     sanitize(row[IndexDict.get(\"i_ref\")]),     \n",
    "                    subj_ref=      subjref,\n",
    "                    nodeID=        sanitize(row[1]),                        #this is a fixed position in dataframe\n",
    "                    wordrole=      WordRole,\n",
    "                    wordrolelong=  WordRoleLong\n",
    "                    )\n",
    "            cv.terminate(this_word)\n",
    "\n",
    "        \n",
    "        '''\n",
    "        wrap up the book. At the end of the book we need to close all nodes in proper order.\n",
    "        '''   \n",
    "        for item in WordGroupList:\n",
    "            #cv.feature(WordGroupDict[(item,4)], add some stats?)\n",
    "            cv.terminate(WordGroupDict[item,4])\n",
    "        #cv.feature(ThisSentencePointer, statdata?)\n",
    "        cv.terminate(ThisSentencePointer)\n",
    "        #cv.feature(ThisVersePointer, statdata?)\n",
    "        cv.terminate(ThisVersePointer)\n",
    "        #cv.feature(ThisChapterPonter, statdata?)\n",
    "        cv.terminate(ThisChapterPointer)      \n",
    "        #cv.feature(ThisBookPointer, statdata?)\n",
    "        cv.terminate(ThisBookPointer)\n",
    "\n",
    "        # clear dataframe for this book, clear the index dictionary\n",
    "        del df\n",
    "        IndexDict.clear()\n",
    "        gc.collect()\n",
    "        \n",
    "        \n",
    "'''\n",
    "-- output definitions --\n",
    "'''  \n",
    "        \n",
    "slotType = 'word'  # or whatever you choose\n",
    "otext = {  # dictionary of config data for sections and text formats\n",
    "        'fmt:text-orig-full':'{word}{after}',\n",
    "        'sectionTypes':'book,chapter,verse',\n",
    "        'sectionFeatures':'book,chapter,verse',\n",
    "        'structureFeatures': 'book,chapter,verse',\n",
    "        'structureTypes': 'book,chapter,verse',\n",
    "        }\n",
    "\n",
    "# configure metadata\n",
    "generic = {  # dictionary of metadata meant for all features\n",
    "         'Name': 'Greek New Testament (NA1904)',\n",
    "         'Version': '1904',\n",
    "         'Editors': 'Nestle',\n",
    "         'Data source': 'MACULA Greek Linguistic Datasets, available at https://github.com/Clear-Bible/macula-greek/tree/main/Nestle1904/lowfat',\n",
    "         'Availability': 'Creative Commons Attribution 4.0 International (CC BY 4.0)', \n",
    "         'Converter_author': 'Tony Jurg, Vrije Universiteit Amsterdam, Netherlands', \n",
    "         'Converter_execution': 'Tony Jurg, Vrije Universiteit Amsterdam, Netherlands', \n",
    "         'Convertor_source': 'https://github.com/tonyjurg/n1904_lft',\n",
    "         'Converter_version': '{}'.format(version),\n",
    "         'TextFabric version': '{}'.format(VERSION)  #imported from tf.parameters\n",
    "         }\n",
    "\n",
    "intFeatures = {  # set of integer valued feature names\n",
    "         'booknumber',\n",
    "         'chapter',\n",
    "         'verse',\n",
    "         'sentence',\n",
    "         'wordgroup',\n",
    "         'orig_order',\n",
    "         'monad'\n",
    "         }\n",
    "\n",
    "featureMeta = {  # per feature dicts with metadata\n",
    "                 'after': {'description': 'Characters (eg. punctuations) following the word'},\n",
    "                 'id': {'description': 'id of the word'},\n",
    "                 'book': {'description': 'Book'},\n",
    "                 'book_long': {'description': 'Book name (fully spelled out)'},\n",
    "                 'booknumber': {'description': 'NT book number (Matthew=1, Mark=2, ..., Revelation=27)'},\n",
    "                 'bookshort': {'description': 'Book name (abbreviated)'},\n",
    "                 'chapter': {'description': 'Chapter number inside book'},\n",
    "                 'verse': {'description': 'Verse number inside chapter'},\n",
    "                 'sentence': {'description': 'Sentence number (counted per chapter)'},\n",
    "                 'type' : {'description': 'Wordgroup type information (verb, verbless, elided, minor, etc.)'},\n",
    "                 'rule' : {'description': 'Wordgroup rule information '},\n",
    "                 'orig_order': {'description': 'Word order within corpus (per book)'},\n",
    "                 'monad':{'description': 'Monad (currently: order of words in XML tree file!)'},\n",
    "                 'word': {'description': 'Word as it appears in the text (excl. punctuations)'},\n",
    "                 'unicode': {'description': 'Word as it arears in the text in Unicode (incl. punctuations)'},\n",
    "                 'ref': {'description': 'ref Id'},\n",
    "                 'sp': {'description': 'Part of Speech (abbreviated)'},\n",
    "                 'sp_full': {'description': 'Part of Speech (long description)'}, \n",
    "                 'normalized': {'description': 'Surface word stripped of punctations'},\n",
    "                 'lemma': {'description': 'Lexeme (lemma)'},\n",
    "                 'morph': {'description': 'Morphological tag (Sandborg-Petersen morphology)'},\n",
    "                 # see also discussion on relation between lex_dom and ln @ https://github.com/Clear-Bible/macula-greek/issues/29\n",
    "                 'lex_dom': {'description': 'Lexical domain according to Semantic Dictionary of Biblical Greek, SDBG (not present everywhere?)'},\n",
    "                 'ln': {'description': 'Lauw-Nida lexical classification (not present everywhere?)'},\n",
    "                 'strongs': {'description': 'Strongs number'},\n",
    "                 'gloss': {'description': 'English gloss'},\n",
    "                 'gn': {'description': 'Gramatical gender (Masculine, Feminine, Neuter)'},\n",
    "                 'nu': {'description': 'Gramatical number (Singular, Plural)'},\n",
    "                 'case': {'description': 'Gramatical case (Nominative, Genitive, Dative, Accusative, Vocative)'},\n",
    "                 'person': {'description': 'Gramatical person of the verb (first, second, third)'},\n",
    "                 'mood': {'description': 'Gramatical mood of the verb (passive, etc)'},\n",
    "                 'tense': {'description': 'Gramatical tense of the verb (e.g. Present, Aorist)'},\n",
    "                 'number': {'description': 'Gramatical number of the verb'},\n",
    "                 'voice': {'description': 'Gramatical voice of the verb'},\n",
    "                 'degree': {'description': 'Degree (e.g. Comparitative, Superlative)'},\n",
    "                 'type': {'description': 'Gramatical type  of noun or pronoun (e.g. Common, Personal)'},\n",
    "                 'reference': {'description': 'Reference (to nodeID in XML source data, not yet post-processes)'},\n",
    "                 'subj_ref': {'description': 'Subject reference (to nodeID in XML source data, not yet post-processes)'},\n",
    "                 'nodeID': {'description': 'Node ID (as in the XML source data, not yet post-processes)'},\n",
    "                 'junction': {'description': 'Junction data related to a wordgroup'},\n",
    "                 'wordgroup' : {'description': 'Wordgroup number (counted per book)'},\n",
    "                 'wgclass' : {'description': 'Class of the wordgroup ()'},\n",
    "                 'wgrole'  : {'description': 'Role of the wordgroup (abbreviated)'},\n",
    "                 'wgrolelong'  : {'description': 'Role of the wordgroup (abbreviated)'},\n",
    "                 'wordrole' : {'description': 'Role of the word (abbreviated)'},\n",
    "                 'wordrolelong': {'description': 'Role of the word (full)'},\n",
    "                 'wgtype': {'description': 'Wordgroup type details'},\n",
    "                 'clausetype': {'description': 'Clause type details'},\n",
    "                 'appos': {'description': 'Apposition details'}\n",
    "                 }\n",
    "\n",
    "'''\n",
    " -- the main function  --\n",
    "'''   \n",
    "\n",
    "good = cv.walk(\n",
    "    director,\n",
    "    slotType,\n",
    "    otext=otext,\n",
    "    generic=generic,\n",
    "    intFeatures=intFeatures,\n",
    "    featureMeta=featureMeta,\n",
    "    warn=True,\n",
    "    force=True\n",
    ")\n",
    "\n",
    "if good:\n",
    "  print (\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc": true
   },
   "source": [
    "## Part 4: Testing the created textfabric data <a class=\"anchor\" id=\"fourth-bullet\"></a>\n",
    "##### [back to TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1 load the TF data\n",
    "\n",
    "The TF will be loaded from github repository https://github.com/tonyjurg/n1904_lft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T02:32:54.197994Z",
     "start_time": "2022-10-21T02:32:53.217806Z"
    }
   },
   "outputs": [],
   "source": [
    "# First, I have to laod different modules that I use for analyzing the data and for plotting:\n",
    "import sys, os, collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "from tf.fabric import Fabric\n",
    "from tf.app import use\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell loads the TextFabric files from github repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T02:32:55.906200Z",
     "start_time": "2022-10-21T02:32:55.012231Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Locating corpus resources ...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b title=\"local commit\">app:</b> <span title=\"#7a5548ba003ea0f8e553bbe23cd9e35f6b098097 offline under C:/Users/tonyj/text-fabric-data/github\">~/text-fabric-data/github/tonyjurg/n1904_lft/app</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b title=\"local commit\">data:</b> <span title=\"#b5b3114fc5b9790c4067ed0c235ba6e408a15678 offline under C:/Users/tonyj/text-fabric-data/github\">~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <b>Text-Fabric:</b> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/tf/cheatsheet.html\" title=\"text-fabric-api\">Text-Fabric API 11.2.3</a>, <a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/app\" title=\"tonyjurg/n1904_lft app\">tonyjurg/n1904_lft/app  v3</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/tf/about/searchusage.html\" title=\"Search Templates Introduction and Reference\">Search Reference</a><br>\n",
       "            <b>Data:</b> <a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/home.md\" title=\"provenance of Nestle 1904\">tonyjurg - n1904_lft 0.1.6</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/tf/writing/\" title=\"How TF features represent text\">Character table</a>, <a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/home.md\" title=\"tonyjurg - n1904_lft feature documentation\">Feature docs</a><br>\n",
       "            <details class=\"nodeinfo\"><summary><b>Node types</b></summary>\n",
       "<table class=\"nodeinfo\">\n",
       "    <tr>\n",
       "        <th>Name</th>\n",
       "        <th># of nodes</th>\n",
       "        <th># slots/node</th>\n",
       "        <th>% coverage</th>\n",
       "    <tr>\n",
       "\n",
       "<tr>\n",
       "    <th>book</th>\n",
       "    <td>27</td>\n",
       "    <td>5102.93</td>\n",
       "    <td><b>100</b></td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "    <th>chapter</th>\n",
       "    <td>260</td>\n",
       "    <td>529.92</td>\n",
       "    <td><b>100</b></td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "    <th>verse</th>\n",
       "    <td>7943</td>\n",
       "    <td>17.35</td>\n",
       "    <td><b>100</b></td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "    <th>sentence</th>\n",
       "    <td>8011</td>\n",
       "    <td>17.20</td>\n",
       "    <td><b>100</b></td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "    <th>wg</th>\n",
       "    <td>113451</td>\n",
       "    <td>7.58</td>\n",
       "    <td><i>624</i></td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "    <th><i>word</i></th>\n",
       "    <td>137779</td>\n",
       "    <td>1.00</td>\n",
       "    <td><b>100</b></td>\n",
       "</tr>\n",
       "</table></details>\n",
       "            <b>Sets:</b> no custom sets<br>\n",
       "            <b>Features:</b><br>\n",
       "<details><summary><b>Nestle 1904</b></summary>\n",
       "    <div class=\"fcorpus\">\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/after.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/after.tf\">after</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Characters (eg. punctuations) following the word</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/appos.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/appos.tf\">appos</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Apposition details</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/book.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/book.tf\">book</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Book</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/book_long.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/book_long.tf\">book_long</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Book name (fully spelled out)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/booknumber.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/booknumber.tf\">booknumber</a>\n",
       "</div>\n",
       "<div class=\"fmono\">int</div>\n",
       "\n",
       "<span> NT book number (Matthew=1, Mark=2, ..., Revelation=27)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/bookshort.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/bookshort.tf\">bookshort</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Book name (abbreviated)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/case.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/case.tf\">case</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Gramatical case (Nominative, Genitive, Dative, Accusative, Vocative)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/chapter.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/chapter.tf\">chapter</a>\n",
       "</div>\n",
       "<div class=\"fmono\">int</div>\n",
       "\n",
       "<span> Chapter number inside book</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/clausetype.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/clausetype.tf\">clausetype</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Clause type details</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/degree.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/degree.tf\">degree</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Degree (e.g. Comparitative, Superlative)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/gloss.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/gloss.tf\">gloss</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> English gloss</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/gn.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/gn.tf\">gn</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Gramatical gender (Masculine, Feminine, Neuter)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/id.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/id.tf\">id</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> id of the word</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/junction.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/junction.tf\">junction</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Junction data related to a wordgroup</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/lemma.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/lemma.tf\">lemma</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Lexeme (lemma)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/lex_dom.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/lex_dom.tf\">lex_dom</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Lexical domain according to Semantic Dictionary of Biblical Greek, SDBG (not present everywhere?)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/ln.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/ln.tf\">ln</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Lauw-Nida lexical classification (not present everywhere?)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/monad.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/monad.tf\">monad</a>\n",
       "</div>\n",
       "<div class=\"fmono\">int</div>\n",
       "\n",
       "<span> Monad (currently: order of words in XML tree file!)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/mood.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/mood.tf\">mood</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Gramatical mood of the verb (passive, etc)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/morph.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/morph.tf\">morph</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Morphological tag (Sandborg-Petersen morphology)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/nodeID.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/nodeID.tf\">nodeID</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Node ID (as in the XML source data, not yet post-processes)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/normalized.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/normalized.tf\">normalized</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Surface word stripped of punctations</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/nu.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/nu.tf\">nu</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Gramatical number (Singular, Plural)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/number.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/number.tf\">number</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Gramatical number of the verb</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/orig_order.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/orig_order.tf\">orig_order</a>\n",
       "</div>\n",
       "<div class=\"fmono\">int</div>\n",
       "\n",
       "<span> Word order within corpus (per book)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/otype.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/otype.tf\">otype</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> </span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/person.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/person.tf\">person</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Gramatical person of the verb (first, second, third)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/ref.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/ref.tf\">ref</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> ref Id</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/rule.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/rule.tf\">rule</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Wordgroup rule information </span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/sentence.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/sentence.tf\">sentence</a>\n",
       "</div>\n",
       "<div class=\"fmono\">int</div>\n",
       "\n",
       "<span> Sentence number (counted per chapter)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/sp.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/sp.tf\">sp</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Part of Speech (abbreviated)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/sp_full.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/sp_full.tf\">sp_full</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Part of Speech (long description)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/strongs.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/strongs.tf\">strongs</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Strongs number</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/subj_ref.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/subj_ref.tf\">subj_ref</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Subject reference (to nodeID in XML source data, not yet post-processes)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/tense.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/tense.tf\">tense</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Gramatical tense of the verb (e.g. Present, Aorist)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/type.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/type.tf\">type</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Gramatical type  of noun or pronoun (e.g. Common, Personal)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/unicode.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/unicode.tf\">unicode</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Word as it arears in the text in Unicode (incl. punctuations)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/verse.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/verse.tf\">verse</a>\n",
       "</div>\n",
       "<div class=\"fmono\">int</div>\n",
       "\n",
       "<span> Verse number inside chapter</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/voice.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/voice.tf\">voice</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Gramatical voice of the verb</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/wgclass.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/wgclass.tf\">wgclass</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Class of the wordgroup ()</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/wgrole.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/wgrole.tf\">wgrole</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Role of the wordgroup (abbreviated)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/wgrolelong.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/wgrolelong.tf\">wgrolelong</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Role of the wordgroup (abbreviated)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/wgtype.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/wgtype.tf\">wgtype</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Wordgroup type details</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/word.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/word.tf\">word</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Word as it appears in the text (excl. punctuations)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/wordgroup.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/wordgroup.tf\">wordgroup</a>\n",
       "</div>\n",
       "<div class=\"fmono\">int</div>\n",
       "\n",
       "<span> Wordgroup number (counted per book)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/wordrole.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/wordrole.tf\">wordrole</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Role of the word (abbreviated)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat \">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/wordrolelong.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/wordrolelong.tf\">wordrolelong</a>\n",
       "</div>\n",
       "<div class=\"fmono\">str</div>\n",
       "\n",
       "<span> Role of the word (full)</span>\n",
       "\n",
       "</div>\n",
       "\n",
       "<div class=\"frow\">\n",
       "    <div class=\"fnamecat edge\">\n",
       "<a target=\"_blank\" href=\"https://github.com/tonyjurg/n1904_lft/blob/master/docs/features/oslots.md\" title=\"~/text-fabric-data/github/tonyjurg/n1904_lft/tf/0.1.6/oslots.tf\">oslots</a>\n",
       "</div>\n",
       "<div class=\"fmono\">none</div>\n",
       "\n",
       "<span> </span>\n",
       "\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "</details>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>tr.tf.ltr, td.tf.ltr, th.tf.ltr { text-align: left ! important;}\n",
       "tr.tf.rtl, td.tf.rtl, th.tf.rtl { text-align: right ! important;}\n",
       "@font-face {\n",
       "  font-family: \"Gentium Plus\";\n",
       "  src: local('Gentium Plus'), local('GentiumPlus'),\n",
       "    url('/server/static/fonts/GentiumPlus-R.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/GentiumPlus-R.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Ezra SIL\";\n",
       "  src: local('Ezra SIL'), local('EzraSIL'),\n",
       "    url('/server/static/fonts/SILEOT.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SILEOT.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"SBL Hebrew\";\n",
       "  src: local('SBL Hebrew'), local('SBLHebrew'),\n",
       "    url('/server/static/fonts/SBL_Hbrw.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SBL_Hbrw.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Estrangelo Edessa\";\n",
       "  src: local('Estrangelo Edessa'), local('EstrangeloEdessa');\n",
       "    url('/server/static/fonts/SyrCOMEdessa.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SyrCOMEdessa.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: AmiriQuran;\n",
       "  font-style: normal;\n",
       "  font-weight: 400;\n",
       "  src: local('Amiri Quran'), local('AmiriQuran'),\n",
       "    url('/server/static/fonts/AmiriQuran.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/AmiriQuran.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: AmiriQuranColored;\n",
       "  font-style: normal;\n",
       "  font-weight: 400;\n",
       "  src: local('Amiri Quran Colored'), local('AmiriQuranColored'),\n",
       "    url('/server/static/fonts/AmiriQuranColored.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/AmiriQuranColored.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Santakku\";\n",
       "  src: local('Santakku'),\n",
       "    url('/server/static/fonts/Santakku.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/Santakku.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"SantakkuM\";\n",
       "  src: local('SantakkuM'),\n",
       "    url('/server/static/fonts/SantakkuM.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SantakkuM.woff?raw=true') format('woff');\n",
       "}\n",
       "/* bypassing some classical notebook settings */\n",
       "div#notebook {\n",
       "  line-height: unset;\n",
       "}\n",
       "/* neutral text */\n",
       ".txtn,.txtn a:visited,.txtn a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* transcription text */\n",
       ".txtt,.txtt a:visited,.txtt a:link {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* source text */\n",
       ".txto,.txto a:visited,.txto a:link {\n",
       "    font-family: serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* phonetic text */\n",
       ".txtp,.txtp a:visited,.txtp a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* original script text */\n",
       ".txtu,.txtu a:visited,.txtu a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* hebrew */\n",
       ".txtu.hbo,.lex.hbo {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* syriac */\n",
       ".txtu.syc,.lex.syc {\n",
       "    font-family: \"Estrangelo Edessa\", sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* neo aramaic */\n",
       ".txtu.cld,.lex.cld {\n",
       "    font-family: \"CharisSIL-R\", sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* standard arabic */\n",
       ".txtu.ara,.lex.ara {\n",
       "    font-family: \"AmiriQuran\", sans-serif;\n",
       "    font-size: large;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* cuneiform */\n",
       ".txtu.akk,.lex.akk {\n",
       "    font-family: Santakku, sans-serif;\n",
       "    font-size: large;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* greek */\n",
       ".txtu.grc,.lex.grc a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "a:hover {\n",
       "    text-decoration: underline | important;\n",
       "    color: #0000ff | important;\n",
       "}\n",
       ".ltr {\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".rtl {\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".ubd {\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".col {\n",
       "   display: inline-block;\n",
       "}\n",
       ".features {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: var(--features);\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    padding: 2px;\n",
       "    margin: 2px;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    border: var(--meta-width) solid var(--meta-color);\n",
       "    border-radius: var(--meta-width);\n",
       "}\n",
       ".features div,.features span {\n",
       "    padding: 0;\n",
       "    margin: -2px 0;\n",
       "}\n",
       ".features .f {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: normal;\n",
       "    color: #5555bb;\n",
       "}\n",
       ".features .xft {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: medium;\n",
       "  margin: 2px 0px;\n",
       "}\n",
       ".features .xft .f {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: small;\n",
       "  font-weight: normal;\n",
       "}\n",
       ".tfsechead {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: var(--tfsechead);\n",
       "    unicode-bidi: embed;\n",
       "    text-align: start;\n",
       "}\n",
       ".structure {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: var(--structure);\n",
       "    unicode-bidi: embed;\n",
       "    text-align: start;\n",
       "}\n",
       ".comments {\n",
       "    display: flex;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    flex-flow: column nowrap;\n",
       "}\n",
       ".nd, a:link.nd {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    color: var(--node);\n",
       "    vertical-align: super;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".lex {\n",
       "  color: var(--lex-color);;\n",
       "}\n",
       ".children,.children.ltr {\n",
       "    display: flex;\n",
       "    border: 0;\n",
       "    background-color: #ffffff;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "}\n",
       ".children.stretch {\n",
       "    align-items: stretch;\n",
       "}\n",
       ".children.hor {\n",
       "    flex-flow: row nowrap;\n",
       "}\n",
       ".children.hor.wrap {\n",
       "    flex-flow: row wrap;\n",
       "}\n",
       ".children.ver {\n",
       "    flex-flow: column nowrap;\n",
       "}\n",
       ".children.ver.wrap {\n",
       "    flex-flow: column wrap;\n",
       "}\n",
       ".contnr {\n",
       "    width: fit-content;\n",
       "    display: flex;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    flex-flow: column nowrap;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding:  10px 2px 2px 2px;\n",
       "    margin: 16px 2px 2px 2px;\n",
       "    border-style: solid;\n",
       "    font-size: small;\n",
       "}\n",
       ".contnr.trm {\n",
       "    background-attachment: local;\n",
       "}\n",
       ".contnr.cnul {\n",
       "    padding:  0;\n",
       "    margin: 0;\n",
       "    border-style: solid;\n",
       "    font-size: xx-small;\n",
       "}\n",
       ".contnr.cnul,.lbl.cnul {\n",
       "    border-color: var(--border-color-nul);\n",
       "    border-width: var(--border-width-nul);\n",
       "    border-radius: var(--border-width-nul);\n",
       "}\n",
       ".contnr.c0,.lbl.c0 {\n",
       "    border-color: var(--border-color0);\n",
       "    border-width: var(--border-width0);\n",
       "    border-radius: var(--border-width0);\n",
       "}\n",
       ".contnr.c1,.lbl.c1 {\n",
       "    border-color: var(--border-color1);\n",
       "    border-width: var(--border-width1);\n",
       "    border-radius: var(--border-width1);\n",
       "}\n",
       ".contnr.c2,.lbl.c2 {\n",
       "    border-color: var(--border-color2);\n",
       "    border-width: var(--border-width2);\n",
       "    border-radius: var(--border-width2);\n",
       "}\n",
       ".contnr.c3,.lbl.c3 {\n",
       "    border-color: var(--border-color3);\n",
       "    border-width: var(--border-width3);\n",
       "    border-radius: var(--border-width3);\n",
       "}\n",
       ".contnr.c4,.lbl.c4 {\n",
       "    border-color: var(--border-color4);\n",
       "    border-width: var(--border-width4);\n",
       "    border-radius: var(--border-width4);\n",
       "}\n",
       "span.plain {\n",
       "    /*display: inline-block;*/\n",
       "    display: inline-flex;\n",
       "    flex-flow: row wrap;\n",
       "    white-space: pre-wrap;\n",
       "}\n",
       ".plain {\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".plain.l,.contnr.l,.contnr.l>.lbl {\n",
       "    border-left-style: dotted\n",
       "}\n",
       ".plain.r,.contnr.r,.contnr.r>.lbl {\n",
       "    border-right-style: dotted\n",
       "}\n",
       ".plain.lno,.contnr.lno,.contnr.lno>.lbl {\n",
       "    border-left-style: none\n",
       "}\n",
       ".plain.rno,.contnr.rno,.contnr.rno>.lbl {\n",
       "    border-right-style: none\n",
       "}\n",
       ".plain.l {\n",
       "    padding-left: 4px;\n",
       "    margin-left: 2px;\n",
       "    border-width: var(--border-width-plain);\n",
       "}\n",
       ".plain.r {\n",
       "    padding-right: 4px;\n",
       "    margin-right: 2px;\n",
       "    border-width: var(--border-width-plain);\n",
       "}\n",
       ".lbl {\n",
       "    font-family: monospace;\n",
       "    margin-top: -24px;\n",
       "    margin-left: 20px;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding: 0 6px;\n",
       "    border-style: solid;\n",
       "    display: block;\n",
       "    color: var(--label)\n",
       "}\n",
       ".lbl.trm {\n",
       "    background-attachment: local;\n",
       "    margin-top: 2px;\n",
       "    margin-left: 2px;\n",
       "    padding: 2px 2px;\n",
       "    border-style: none;\n",
       "}\n",
       ".lbl.cnul {\n",
       "    font-size: xx-small;\n",
       "}\n",
       ".lbl.c0 {\n",
       "    font-size: small;\n",
       "}\n",
       ".lbl.c1 {\n",
       "    font-size: small;\n",
       "}\n",
       ".lbl.c2 {\n",
       "    font-size: medium;\n",
       "}\n",
       ".lbl.c3 {\n",
       "    font-size: medium;\n",
       "}\n",
       ".lbl.c4 {\n",
       "    font-size: large;\n",
       "}\n",
       ".occs, a:link.occs {\n",
       "    font-size: small;\n",
       "}\n",
       "\n",
       "/* PROVENANCE */\n",
       "\n",
       "div.prov {\n",
       "\tmargin: 40px;\n",
       "\tpadding: 20px;\n",
       "\tborder: 2px solid var(--fog-rim);\n",
       "}\n",
       "div.pline {\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "}\n",
       "div.p2line {\n",
       "\tmargin-left: 2em;\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "}\n",
       "div.psline {\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "\tbackground-color: var(--gold-mist-back);\n",
       "}\n",
       "div.pname {\n",
       "\tflex: 0 0 5rem;\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.pval {\n",
       "    flex: 1 1 auto;\n",
       "}\n",
       "\n",
       "/* KEYBOARD */\n",
       ".ccoff {\n",
       "  background-color: inherit;\n",
       "}\n",
       ".ccon {\n",
       "  background-color: yellow ! important;\n",
       "}\n",
       ".ccon,.ccoff {\n",
       "  padding: 0.2rem;\n",
       "  margin: 0.2rem;\n",
       "  border: 0.1rem solid var(--letter-box-border);\n",
       "  border-radius: 0.1rem;\n",
       "}\n",
       ".ccline {\n",
       "  font-size: xx-large ! important;\n",
       "  font-weight: bold;\n",
       "  line-height: 2em ! important;\n",
       "}\n",
       "/* TF header */\n",
       "\n",
       "summary {\n",
       "  /* needed to override the normalize.less\n",
       "   * in the classical jupyter notebook\n",
       "   */\n",
       "  display: list-item ! important;\n",
       "}\n",
       "\n",
       ".fcorpus {\n",
       "  display: flex;\n",
       "  flex-flow: column nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: flex-start;\n",
       "  align-content: flex-start;\n",
       "}\n",
       ".frow {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: flex-start;\n",
       "  align-content: flex-start;\n",
       "}\n",
       ".fmeta {\n",
       "  display: flex;\n",
       "  flex-flow: column nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: flex-start;\n",
       "  align-content: flex-start;\n",
       "}\n",
       ".fmetarow {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: flex-start;\n",
       "  align-content: flex-start;\n",
       "}\n",
       ".fmetakey {\n",
       "  min-width: 8em;\n",
       "  font-family: monospace;\n",
       "}\n",
       ".fnamecat {\n",
       "  min-width: 8em;\n",
       "}\n",
       ".fnamecat.edge {\n",
       "  font-weight: bold;\n",
       "  font-style: italic;\n",
       "}\n",
       ".fmono {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--node:               hsla(120, 100%,  20%, 1.0  );\n",
       "\t--label:              hsla(  0, 100%,  20%, 1.0  );\n",
       "\t--tfsechead:          hsla(  0, 100%,  25%, 1.0  );\n",
       "\t--structure:          hsla(120, 100%,  25%, 1.0  );\n",
       "\t--features:           hsla(  0,   0%,  30%, 1.0  );\n",
       "  --text-color:         hsla( 60,  80%,  10%, 1.0  );\n",
       "  --lex-color:          hsla(220,  90%,  60%, 1.0  );\n",
       "  --meta-color:         hsla(  0,   0%,  90%, 0.7  );\n",
       "  --meta-width:         3px;\n",
       "  --border-color-nul:   hsla(  0,   0%,  90%, 0.5  );\n",
       "  --border-color0:      hsla(  0,   0%,  90%, 0.9  );\n",
       "  --border-color1:      hsla(  0,   0%,  80%, 0.9  );\n",
       "  --border-color2:      hsla(  0,   0%,  70%, 0.9  );\n",
       "  --border-color3:      hsla(  0,   0%,  80%, 0.8  );\n",
       "  --border-color4:      hsla(  0,   0%,  60%, 0.9  );\n",
       "\t--letter-box-border:  hsla(  0,   0%,  80%, 0.5  );\n",
       "  --border-width-nul:   2px;\n",
       "  --border-width0:      2px;\n",
       "  --border-width1:      3px;\n",
       "  --border-width2:      4px;\n",
       "  --border-width3:      6px;\n",
       "  --border-width4:      5px;\n",
       "  --border-width-plain: 2px;\n",
       "}\n",
       ".hl {\n",
       "  background-color: var(--hl-strong);\n",
       "}\n",
       "span.hl {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder-width: 0;\n",
       "\tborder-radius: 2px;\n",
       "\tborder-style: solid;\n",
       "}\n",
       "div.contnr.hl,div.lbl.hl {\n",
       "  background-color: var(--hl-strong);\n",
       "}\n",
       "div.contnr.hl {\n",
       "  border-color: var(--hl-rim) ! important;\n",
       "\tborder-width: 4px ! important;\n",
       "}\n",
       "\n",
       "span.hlbx {\n",
       "\tborder-color: var(--hl-rim);\n",
       "\tborder-width: 4px ! important;\n",
       "\tborder-style: solid;\n",
       "\tborder-radius: 6px;\n",
       "  padding: 4px;\n",
       "  margin: 4px;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--hl-strong:        hsla( 60, 100%,  70%, 0.9  );\n",
       "\t--hl-rim:           hsla( 55,  80%,  50%, 1.0  );\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<script>\n",
       "globalThis.copyChar = (el, c) => {\n",
       "    for (const el of document.getElementsByClassName('ccon')) {\n",
       "        el.className = 'ccoff'\n",
       "    }\n",
       "    el.className = 'ccon'\n",
       "    navigator.clipboard.writeText(String.fromCharCode(c))\n",
       "}\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Text-Fabric API:</b> names <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/tf/cheatsheet.html\" title=\"doc\">N F E L T S C TF</a> directly usable</div><hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading-the-New-Testament-Text-Fabric (add a specific version, eg. 0.1.2)\n",
    "NA = use (\"tonyjurg/n1904_lft\", version=\"0.1.6\", hoist=globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 0, 'wg': 1, 'sentence': 2, 'verse': 3, 'chapter': 4, 'book': 5}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N.otypeRank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text-orig-full': 'word'}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 Perform some basic display \n",
    "\n",
    "note: the implementation with regards how phrases need to be displayed (esp. with regards to conjunctions) is still to be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.01s 25 results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><b>verse</b> <i>1</i>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tfsechead \"><span class=\"ltr\"><a target=\"_blank\" href=\"https://bibleol.3bmoodle.dk/text/show_text/nestle1904/Matthew/1/1\" sec=\"Matthew 1:1\">Matthew 1:1</a></span></div><div class=\" children\"><div class=\"contnr c3    \" ><div class=\"lbl c3  \" ><span class=\"nd\">verse </span> <span class=\"\"><span title=\"verse\">1</span></span></div><div class=\"children hor wrap \"><div class=\"contnr c1    \" ><div class=\"lbl c1  \" ><span class=\"nd\">sentence </span> <span class=\"\"><span title=\"sentence\"></span></span></div><div class=\"children hor wrap \"><div class=\"contnr c1    \" ><div class=\"lbl c1  \" ><span class=\"nd\">wg </span> <span class=\"{color: red;}\"><span title=\"rule\"></span> <span title=\"clausetype\"></span> <span title=\"wgrolelong\"></span> <span title=\"junction\"></span></span></div><div class=\"children hor wrap \"><div class=\"contnr c1    \" ><div class=\"lbl c1  \" ><span class=\"nd\">wg </span> <span class=\"{color: red;}\"><span title=\"rule\">P2CL</span> <span title=\"clausetype\">Verbless</span> <span title=\"wgrolelong\"></span> <span title=\"junction\"></span></span></div><div class=\"children hor wrap \"><div class=\"contnr c1    \" ><div class=\"lbl c1  \" ><span class=\"nd\">wg </span> <span class=\"{color: red;}\"><span title=\"rule\">NPofNP</span> <span title=\"clausetype\"></span> <span title=\"wgrolelong\">Predicate</span> <span title=\"junction\"></span></span></div><div class=\"children hor wrap \"><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">Βίβλος </span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>[The] book</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>noun</span></div></div><div class=\"contnr c1    \" ><div class=\"lbl c1  \" ><span class=\"nd\">wg </span> <span class=\"{color: red;}\"><span title=\"rule\">NPofNP</span> <span title=\"clausetype\"></span> <span title=\"wgrolelong\"></span> <span title=\"junction\"></span></span></div><div class=\"children hor wrap \"><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">γενέσεως </span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>of [the] genealogy</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>noun</span></div></div><div class=\"contnr c1    \" ><div class=\"lbl c1  \" ><span class=\"nd\">wg </span> <span class=\"{color: red;}\"><span title=\"rule\">Np-Appos</span> <span title=\"clausetype\"></span> <span title=\"wgrolelong\"></span> <span title=\"junction\"></span></span></div><div class=\"children hor wrap \"><div class=\"contnr c1    \" ><div class=\"lbl c1  \" ><span class=\"nd\">wg </span> <span class=\"{color: red;}\"><span title=\"rule\">Np-Appos</span> <span title=\"clausetype\"></span> <span title=\"wgrolelong\"></span> <span title=\"junction\"></span></span></div><div class=\"children hor wrap \"><div class=\"contnr c1    \" ><div class=\"lbl c1  \" ><span class=\"nd\">wg </span> <span class=\"{color: red;}\"><span title=\"rule\">Np-Appos</span> <span title=\"clausetype\"></span> <span title=\"wgrolelong\"></span> <span title=\"junction\"></span></span></div><div class=\"children hor wrap \"><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">Ἰησοῦ </span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>of Jesus</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>noun</span></div></div><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">Χριστοῦ </span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>Christ</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>noun</span></div></div></div></div><div class=\"contnr c1    \" ><div class=\"lbl c1  \" ><span class=\"nd\">wg </span> <span class=\"{color: red;}\"><span title=\"rule\">NPofNP</span> <span title=\"clausetype\"></span> <span title=\"wgrolelong\"></span> <span title=\"junction\">apposition</span></span></div><div class=\"children hor wrap \"><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">υἱοῦ </span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>son</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>noun</span></div></div><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">Δαυεὶδ </span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>of David</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>noun</span></div></div></div></div></div></div><div class=\"contnr c1    \" ><div class=\"lbl c1  \" ><span class=\"nd\">wg </span> <span class=\"{color: red;}\"><span title=\"rule\">NPofNP</span> <span title=\"clausetype\"></span> <span title=\"wgrolelong\"></span> <span title=\"junction\">apposition</span></span></div><div class=\"children hor wrap \"><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">υἱοῦ </span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>son</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>noun</span></div></div><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">Ἀβραάμ.</span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>of Abraham</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>noun</span></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><b>verse</b> <i>2</i>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tfsechead \"><span class=\"ltr\"><a target=\"_blank\" href=\"https://bibleol.3bmoodle.dk/text/show_text/nestle1904/Matthew/1/2\" sec=\"Matthew 1:2\">Matthew 1:2</a></span></div><div class=\" children\"><div class=\"contnr c3    \" ><div class=\"lbl c3  \" ><span class=\"nd\">verse </span> <span class=\"\"><span title=\"verse\">2</span></span></div><div class=\"children hor wrap \"><div class=\"contnr c1   rno \" ><div class=\"lbl c1  \" ><span class=\"nd\">sentence </span> <span class=\"\"><span title=\"sentence\"></span></span></div><div class=\"children hor wrap \"><div class=\"contnr c1   rno \" ><div class=\"lbl c1  \" ><span class=\"nd\">wg </span> <span class=\"{color: red;}\"><span title=\"rule\"></span> <span title=\"clausetype\"></span> <span title=\"wgrolelong\"></span> <span title=\"junction\"></span></span></div><div class=\"children hor wrap \"><div class=\"contnr c1   rno \" ><div class=\"lbl c1  \" ><span class=\"nd\">wg </span> <span class=\"{color: red;}\"><span title=\"rule\">Conj13CL</span> <span title=\"clausetype\"></span> <span title=\"wgrolelong\"></span> <span title=\"junction\"></span></span></div><div class=\"children hor wrap \"><div class=\"contnr c1    \" ><div class=\"lbl c1  \" ><span class=\"nd\">wg </span> <span class=\"{color: red;}\"><span title=\"rule\">S-V-O</span> <span title=\"clausetype\"></span> <span title=\"wgrolelong\"></span> <span title=\"junction\">coordinate</span></span></div><div class=\"children hor wrap \"><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">Ἀβραὰμ </span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>Abraham</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>noun</span><span class=\"wordrolelong xft\" ><span class=\"f\">wordrolelong=</span>Subject</span></div></div><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">ἐγέννησεν </span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>begat</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>verb</span><span class=\"wordrolelong xft\" ><span class=\"f\">wordrolelong=</span>Verbal</span></div></div><div class=\"contnr c1    \" ><div class=\"lbl c1  \" ><span class=\"nd\">wg </span> <span class=\"{color: red;}\"><span title=\"rule\">DetNP</span> <span title=\"clausetype\"></span> <span title=\"wgrolelong\">Object</span> <span title=\"junction\"></span></span></div><div class=\"children hor wrap \"><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">τὸν </span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>-</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>det</span></div></div><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">Ἰσαάκ,</span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>Isaac</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>noun</span></div></div></div></div></div></div><div class=\"contnr c1    \" ><div class=\"lbl c1  \" ><span class=\"nd\">wg </span> <span class=\"{color: red;}\"><span title=\"rule\"></span> <span title=\"clausetype\"></span> <span title=\"wgrolelong\"></span> <span title=\"junction\"></span></span></div><div class=\"children hor wrap \"><div class=\"contnr c1   r \" ><div class=\"lbl c1  \" ><span class=\"nd\">wg </span> <span class=\"{color: red;}\"><span title=\"rule\">S-V-O</span> <span title=\"clausetype\"></span> <span title=\"wgrolelong\"></span> <span title=\"junction\">coordinate</span></span></div><div class=\"children hor wrap \"><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">Ἰσαὰκ </span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>Isaac</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>noun</span><span class=\"wordrolelong xft\" ><span class=\"f\">wordrolelong=</span>Subject</span></div></div></div></div><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">δὲ </span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>then</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>conj</span></div></div><div class=\"contnr c1   l \" ><div class=\"lbl c1  \" ><span class=\"nd\">wg </span> <span class=\"{color: red;}\"><span title=\"rule\">S-V-O</span> <span title=\"clausetype\"></span> <span title=\"wgrolelong\"></span> <span title=\"junction\">coordinate</span></span></div><div class=\"children hor wrap \"><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">ἐγέννησεν </span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>begat</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>verb</span><span class=\"wordrolelong xft\" ><span class=\"f\">wordrolelong=</span>Verbal</span></div></div><div class=\"contnr c1    \" ><div class=\"lbl c1  \" ><span class=\"nd\">wg </span> <span class=\"{color: red;}\"><span title=\"rule\">DetNP</span> <span title=\"clausetype\"></span> <span title=\"wgrolelong\">Object</span> <span title=\"junction\"></span></span></div><div class=\"children hor wrap \"><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">τὸν </span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>-</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>det</span></div></div><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">Ἰακώβ,</span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>Jacob</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>noun</span></div></div></div></div></div></div></div></div><div class=\"contnr c1    \" ><div class=\"lbl c1  \" ><span class=\"nd\">wg </span> <span class=\"{color: red;}\"><span title=\"rule\"></span> <span title=\"clausetype\"></span> <span title=\"wgrolelong\"></span> <span title=\"junction\"></span></span></div><div class=\"children hor wrap \"><div class=\"contnr c1   r \" ><div class=\"lbl c1  \" ><span class=\"nd\">wg </span> <span class=\"{color: red;}\"><span title=\"rule\">S-V-O</span> <span title=\"clausetype\"></span> <span title=\"wgrolelong\"></span> <span title=\"junction\">coordinate</span></span></div><div class=\"children hor wrap \"><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">Ἰακὼβ </span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>Jacob</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>noun</span><span class=\"wordrolelong xft\" ><span class=\"f\">wordrolelong=</span>Subject</span></div></div></div></div><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">δὲ </span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>then</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>conj</span></div></div><div class=\"contnr c1   l \" ><div class=\"lbl c1  \" ><span class=\"nd\">wg </span> <span class=\"{color: red;}\"><span title=\"rule\">S-V-O</span> <span title=\"clausetype\"></span> <span title=\"wgrolelong\"></span> <span title=\"junction\">coordinate</span></span></div><div class=\"children hor wrap \"><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">ἐγέννησεν </span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>begat</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>verb</span><span class=\"wordrolelong xft\" ><span class=\"f\">wordrolelong=</span>Verbal</span></div></div><div class=\"contnr c1    \" ><div class=\"lbl c1  \" ><span class=\"nd\">wg </span> <span class=\"{color: red;}\"><span title=\"rule\">NpaNp</span> <span title=\"clausetype\"></span> <span title=\"wgrolelong\">Object</span> <span title=\"junction\"></span></span></div><div class=\"children hor wrap \"><div class=\"contnr c1    \" ><div class=\"lbl c1  \" ><span class=\"nd\">wg </span> <span class=\"{color: red;}\"><span title=\"rule\">DetNP</span> <span title=\"clausetype\"></span> <span title=\"wgrolelong\"></span> <span title=\"junction\"></span></span></div><div class=\"children hor wrap \"><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">τὸν </span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>-</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>det</span></div></div><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">Ἰούδαν </span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>Judah</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>noun</span></div></div></div></div><div class=\"contnr c1    \" ><div class=\"lbl c1  \" ><span class=\"nd\">wg </span> <span class=\"{color: red;}\"><span title=\"rule\"></span> <span title=\"clausetype\"></span> <span title=\"wgrolelong\"></span> <span title=\"junction\"></span></span></div><div class=\"children hor wrap \"><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">καὶ </span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>and</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>conj</span></div></div><div class=\"contnr c1    \" ><div class=\"lbl c1  \" ><span class=\"nd\">wg </span> <span class=\"{color: red;}\"><span title=\"rule\">DetNP</span> <span title=\"clausetype\"></span> <span title=\"wgrolelong\"></span> <span title=\"junction\"></span></span></div><div class=\"children hor wrap \"><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">τοὺς </span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>the</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>det</span></div></div><div class=\"contnr c1    \" ><div class=\"lbl c1  \" ><span class=\"nd\">wg </span> <span class=\"{color: red;}\"><span title=\"rule\">NPofNP</span> <span title=\"clausetype\"></span> <span title=\"wgrolelong\"></span> <span title=\"junction\"></span></span></div><div class=\"children hor wrap \"><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">ἀδελφοὺς </span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>brothers</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>noun</span></div></div><div class=\"contnr c0 trm   \" ><div class=\"lbl c0 trm \" ><span class=\"txtu\">αὐτοῦ,</span></div><div class='features'><span class=\"gloss xft\" ><span class=\"f\">gloss=</span>of him</span><span class=\"sp xft\" ><span class=\"f\">sp=</span>pron</span></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Search0 = '''\n",
    "book book=Matthew\n",
    "  chapter chapter=1\n",
    "  \n",
    "     verse \n",
    "'''\n",
    "Search0 = NA.search(Search0)\n",
    "NA.show(Search0, start=1, end=2, condensed=True, extraFeatures={'sp','gloss','wordrolelong'},  suppress={'chapter'}, withNodes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 dump some structure information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A heading is a tuple of pairs (node type, feature value)\n",
      "\tof node types and features that have been configured as structural elements\n",
      "These 3 structural elements have been configured\n",
      "\tnode type book       with heading feature book\n",
      "\tnode type chapter    with heading feature chapter\n",
      "\tnode type verse      with heading feature verse\n",
      "You can get them as a tuple with T.headings.\n",
      "\n",
      "Structure API:\n",
      "\tT.structure(node=None)       gives the structure below node, or everything if node is None\n",
      "\tT.structurePretty(node=None) prints the structure below node, or everything if node is None\n",
      "\tT.top()                      gives all top-level nodes\n",
      "\tT.up(node)                   gives the (immediate) parent node\n",
      "\tT.down(node)                 gives the (immediate) children nodes\n",
      "\tT.headingFromNode(node)      gives the heading of a node\n",
      "\tT.nodeFromHeading(heading)   gives the node of a heading\n",
      "\tT.ndFromHd                   complete mapping from headings to nodes\n",
      "\tT.hdFromNd                   complete mapping from nodes to headings\n",
      "\tT.hdMult are all headings    with their nodes that occur multiple times\n",
      "\n",
      "There are 8230 structural elements in the dataset.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "T.structureInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Availability': 'Creative Commons Attribution 4.0 International (CC BY 4.0)',\n",
       " 'Converter_author': 'Tony Jurg, Vrije Universiteit Amsterdam, Netherlands',\n",
       " 'Converter_execution': 'Tony Jurg, Vrije Universiteit Amsterdam, Netherlands',\n",
       " 'Converter_version': '0.1.6 (moved all phrases and claused to wordgroup nodes)',\n",
       " 'Convertor_source': 'https://github.com/tonyjurg/n1904_lft',\n",
       " 'Data source': 'MACULA Greek Linguistic Datasets, available at https://github.com/Clear-Bible/macula-greek/tree/main/Nestle1904/lowfat',\n",
       " 'Editors': 'Nestle',\n",
       " 'Name': 'Greek New Testament (NA1904)',\n",
       " 'TextFabric version': '11.2.3',\n",
       " 'Version': '1904',\n",
       " 'fmt:text-orig-full': '{word}{after}',\n",
       " 'sectionFeatures': 'book,chapter,verse',\n",
       " 'sectionTypes': 'book,chapter,verse',\n",
       " 'structureFeatures': 'book,chapter,verse',\n",
       " 'structureTypes': 'book,chapter,verse',\n",
       " 'writtenBy': 'Text-Fabric',\n",
       " 'dateWritten': '2023-05-02T15:20:37Z'}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF.features['otext'].metaData\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running text fabric browser <a class=\"anchor\" id=\"fourth-bullet\"></a>\n",
    "##### [back to TOC](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!text-fabric app "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!text-fabric app -k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [135]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mNodes\u001b[38;5;241m.\u001b[39motypeRank\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "tf.core.nodes.Nodes.otypeRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "321.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
